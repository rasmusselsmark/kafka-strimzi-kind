apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaNodePool
metadata:
  name: broker
  namespace: kafka
  labels:
    strimzi.io/cluster: kafka-cluster
spec:
  replicas: 3
  roles:
    - broker
    - controller
  storage:
    type: jbod
    volumes:
      - id: 0
        type: persistent-claim
        size: 10Gi
        class: standard
  resources:
    requests:
      memory: 1Gi
      cpu: 500m
    limits:
      memory: 2Gi
      cpu: 1000m
  jvmOptions:
    -Xms: 1g
    -Xmx: 1g
  # Ensure brokers are distributed across nodes
  template:
    pod:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: strimzi.io/name
                    operator: In
                    values:
                      - kafka-cluster-broker
              topologyKey: kubernetes.io/hostname
---
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: kafka-cluster
  namespace: kafka
  annotations:
    strimzi.io/node-pools: enabled
spec:
  kafka:
    version: 4.1.0
    metadataVersion: 4.1-IV0
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
      - name: tls
        port: 9093
        type: internal
        tls: true
    config:
      # Replication and reliability settings
      default.replication.factor: 3
      min.insync.replicas: 2
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      # Performance settings
      num.network.threads: 3
      num.io.threads: 8
      socket.send.buffer.bytes: 102400
      socket.receive.buffer.bytes: 102400
      socket.request.max.bytes: 104857600
      # Storage settings
      num.partitions: 3
      num.recovery.threads.per.data.dir: 1
      log.retention.hours: 168
      log.segment.bytes: 1073741824
      log.retention.check.interval.ms: 300000
      # Consumer settings
      group.initial.rebalance.delay.ms: 0
  entityOperator:
    topicOperator: {}
    userOperator: {}
  kafkaExporter: {}
  cruiseControl:
    brokerCapacity:
      inboundNetwork: 10000KB/s
      outboundNetwork: 10000KB/s
    # config:
    #   # Cruise Control goals for rebalancing
    #   default.goals: >
    #     com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal,
    #     com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal,
    #     com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal,
    #     com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal,
    #     com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal,
    #     com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuCapacityGoal,
    #     com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionGoal,
    #     com.linkedin.kafka.cruisecontrol.analyzer.goals.PotentialNwOutGoal,
    #     com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskUsageDistributionGoal,
    #     com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundUsageDistributionGoal,
    #     com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundUsageDistributionGoal,
    #     com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuUsageDistributionGoal,
    #     com.linkedin.kafka.cruisecontrol.analyzer.goals.TopicReplicaDistributionGoal,
    #     com.linkedin.kafka.cruisecontrol.analyzer.goals.LeaderReplicaDistributionGoal,
    #     com.linkedin.kafka.cruisecontrol.analyzer.goals.LeaderBytesInDistributionGoal
    #   # Metrics collection interval (increased to avoid timeout issues)
    #   metric.sampling.interval.ms: 120000
    #   # Number of metric samples to keep
    #   num.metric.windows: 5
    #   # Metadata refresh timeout must be less than sampling interval
    #   metadata.max.age.ms: 100000
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        cpu: 500m
        memory: 1Gi
